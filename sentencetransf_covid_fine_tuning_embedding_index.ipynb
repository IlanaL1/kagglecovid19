{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "sentencetransf-covid-fine-tuning-embedding-index.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IlanaL1/kagglecovid19/blob/master/sentencetransf_covid_fine_tuning_embedding_index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziMua5htbBa-",
        "colab_type": "text"
      },
      "source": [
        "#### Create an Embeddings Index\n",
        "\n",
        "This Script produces an embedding index that allows a researcher to perform a semantic similarity search on the cord-19 dataset. It has a few features\n",
        "\n",
        "- You can search an index (Faiss) for sentences with semantic similarity to an input query. \n",
        "    - The sentences are constructued using sentence embeddings (SentenceTransformer library)\n",
        "    - SentenceTransformer is initialised with covid-bert-base, and then fine-tuned with NLI and STS tasks so it adds semantic components to the underlying covid based language model. \n",
        "    \n",
        "- A search filter function allows you to limit the documents compiled into the semantic index, by keyword; \n",
        "    - If the keyword appears in the documents precompiled \"list of entities\", the document is inclued in the index. \n",
        "    - The keywords are detected with scipacy,\n",
        "\n",
        "Briefly, the following steps are performed.  . \n",
        "\n",
        "- Report \n",
        "\n",
        "- Part A\n",
        "    - Step 1: Initialise SentenceTransfomer model with covid_bert_base (https://huggingface.co/deepset/covid_bert_base)\n",
        "    - Step 2: Fine-tune SentenceTransformer model with natural language inference (sentence entailment) and semantic similarity (sts) tasks\n",
        " \n",
        "\n",
        " - Part B \n",
        "\n",
        "    - This part is divided into Part B.1 and Part B.2\n",
        "\n",
        "    - Part B.1 is run on Kaggle kernel. It generates a dataframe with columns paper_id, abstract and body_text.\n",
        "\n",
        "    - Part B.2 was run on Google Colab, which connects to a GCP VM, with 16 cores to allow efficient multiprocessin- g of dataframe batches. . I included the code here to view. This part takes the dataframe from B.1, and uses scispacy to extract scientific entities, and creates a new column \"ents\" in the dataframe. \n",
        "\n",
        "-  Part C \n",
        " -   Create Faiss Index for each sentence within corpus \n",
        "  \n",
        "\n",
        "## TO DO\n",
        "still missing some abstracts which means filtering should look at first seciton of body_text for ents...\n",
        "\n",
        "search function should be refactored, nlp(doc) should be factored out so its only performed once for each doc \n",
        "\n",
        "memory usage is too high. Need to rethink use of garbage collector, or more memory efficient table storage\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "id": "PYkh4MvgbBbD",
        "colab_type": "text"
      },
      "source": [
        "## References \n",
        "\n",
        "#### Kaggle Kernels \n",
        "\n",
        "-  https://www.kaggle.com/xhlulu/cord-19-eda-parse-json-and-generate-clean-csv\n",
        "- https://www.kaggle.com/maksimeren/covid-19-literature-clustering\n",
        "\n",
        "\n",
        "These kernels provided code cells cut+pasted into this notebook. They have been to used generate a clean dataset through parsing json files. Many thanks. \n",
        "\n",
        "\n",
        "#### Spacy\n",
        "\n",
        "- https://spacy.io/\n",
        "\n",
        "Spacy is used to perform nlp pipeline functions such as tokenization, sentence segmentation and span retrieval\n",
        "\n",
        "#### deepset/covid-bert-base\n",
        "\n",
        "- https://huggingface.co/deepset/covid_bert_base\n",
        "- https://github.com/deepset-ai/FARM/blob/master/examples/lm_finetuning.py \n",
        "\n",
        "DeepsetAI script showing how to fine-tune BERT language model with a language modeling task. From what I can gather, they used script lm_finetuning.py in their FARM tools using the CORD-19 dataset to fine-tune the model. \n",
        "\n",
        "#### SentenceTransformers\n",
        "- https://github.com/UKPLab/sentence-transformers\n",
        "- https://github.com/UKPLab/sentence-transformers/blob/master/examples/training_nli_bert.py\n",
        "\n",
        "After loading the covid-bert model, we continued to fine-tune the sentence-transformer model to perform well of natural language tasks, since we will be performing these sorts of tasks when runnning our searches on the embeddings-index. \n",
        "\n",
        "#### Faiss\n",
        "- https://gist.github.com/mdouze/e30e8f57a98ed841c082cc68baa14b4a\n",
        "This provides code to serialise and deserialise the index so it can be pickled. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtZww5N8bRo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle\n",
        "## use supported backend for now. \n",
        "#carve df_covid into 5 bits. \n",
        "#later if you can get local backend working , can do that. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soYltoMMc9y1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "75ef5e6c-f2b1-49ec-befc-2c614c300b37"
      },
      "source": [
        "# to connect to kaggle, you need to get kaggle.json across - cant do this from local notebook\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgHFYGRcdK1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "aa1138d4-ad5f-43ad-c9ad-d8cf5acae693"
      },
      "source": [
        "!kaggle datasets list --user 'ilanal' --sort-by active\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bqn7oXqdUNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!kaggle datasets download ilanal/cord-df-with-entities \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXFW4sS_eDfJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fae0135e-2126-48e7-8167-b3ef2eb7cffc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz57LYOjddix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "04877be9-5b11-4846-9cff-fc13d62f21b7"
      },
      "source": [
        "!unzip \"/content/drive/My Drive/kaggle/covid19/input/df_ents.zip.zip\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/kaggle/covid19/input/df_ents.zip.zip\n",
            "  inflating: 1.csv                   \n",
            "  inflating: 2.csv                   \n",
            "  inflating: 3.csv                   \n",
            "  inflating: 4.csv                   \n",
            "  inflating: 5.csv                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phB2ypewbBbS",
        "colab_type": "text"
      },
      "source": [
        "### Setup and Installation  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wQqUc4b_bBbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display full output in Jupyter notebook cell (not only final statement)\n",
        "from __future__ import print_function\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-u2lQNoabBbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# torch from pytorch (huggingface)\n",
        "import torch\n",
        "#from transformers import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "import collections\n",
        "from tqdm import tqdm\n",
        "import pprint\n",
        "\n",
        "tqdm.pandas(desc=\"my bar!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ew206-JMbBbp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d079b835-cb2d-4190-a865-036d3d9c0253"
      },
      "source": [
        "# if using GPU, test GPU is working\n",
        "cuda = torch.device('cuda')     # Default CUDA device\n",
        "torch.__version__\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yeHblkEGbBb0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5229b456-c8b1-4a73-c91b-21293388ddfc"
      },
      "source": [
        "# set display options\n",
        "pd.options.display.max_rows\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.expand_frame_repr', False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PrClvpT3bBb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "# clone sentence-transformers code and examples, and install\n",
        "# install sentence-transformers and download repo to perform fine-tuning steps. pip install will not give you access to all the examples\n",
        "\n",
        "!git clone https://github.com/UKPLab/sentence-transformers.git\n",
        "os.chdir(\"sentence-transformers\")\n",
        "!pip install -e ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak5F51-5i7hU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#os.chdir(\"..\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ttI10cbPbBcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "# Install spacy and scispacy, and scispacy language model\n",
        "!pip install scispacy\n",
        "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Rlx0wCY7bBcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scispacy\n",
        "import spacy\n",
        "import en_core_sci_sm\n",
        "#nlp=spacy.load(\"en_core_sci_sm\") # not working\n",
        "nlp = en_core_sci_sm.load()\n",
        "nlp.max_length=100000000 # for extra long documents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oudbwc_nuXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install sentence-transformers\n",
        "#import os\n",
        "#os.chdir(\"/content/sentence-transformers\")\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5MQeRxMobBcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "%%capture\n",
        "# install faiss \n",
        "#!pip install faiss-gpu\n",
        "import faiss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "a-efpFiMbBcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define some generic functions\n",
        "\n",
        "# define sentence_embedding function\n",
        "def embed_sentence_list(model,list_of_sents):\n",
        "    sentence_embeddings=model.encode(list_of_sents)\n",
        "    doc_matrix=np.asarray(sentence_embeddings,dtype=np.float32)\n",
        "    return(doc_matrix)\n",
        "\n",
        "\n",
        "# we need to serialise faiss index to save it to output\n",
        "#https://gist.github.com/mdouze/e30e8f57a98ed841c082cc68baa14b4a\n",
        "\n",
        "def serialize_index(index):\n",
        "    \"\"\" convert an index to a numpy uint8 array  \"\"\"\n",
        "    writer = faiss.VectorIOWriter()\n",
        "    faiss.write_index(index, writer)\n",
        "    return faiss.vector_to_array(writer.data)\n",
        "\n",
        "\n",
        "def deserialize_index(data):\n",
        "    reader = faiss.VectorIOReader()\n",
        "    faiss.copy_array_to_vector(data, reader.data)\n",
        "    return faiss.read_index(reader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6jWPzZobBce",
        "colab_type": "text"
      },
      "source": [
        "### End of Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4WRhmuxbBcf",
        "colab_type": "text"
      },
      "source": [
        "## Report: Semantic Search for limited documents \n",
        "\n",
        "This section contains the report, and assumes Part A, B and C have been run. We can load pre-built objects from those sections from the input directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "srHrakPnbBcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load pre-built faiss index from input\n",
        "# This contains an embedding for each sentence, for each document\n",
        "# The sentence embedding model has been trained as per Part A, below. \n",
        "\n",
        "def read_full_faiss_index():\n",
        "    filepath=\"/content/drive/My Drive/kaggle/covid19/input/index_faiss_file_all\"\n",
        "    file=open(filepath, \"rb\")\n",
        "    data=pickle.load(file)\n",
        "    faiss_index=deserialize_index(data)\n",
        "\n",
        "    # convert index from cpu to gpu\n",
        "    res = faiss.StandardGpuResources()  # use a single GPUres = faiss.StandardGpuResources()  # use a single GPU\n",
        "    gpu_index = faiss.index_cpu_to_gpu(res, 0, faiss_index)\n",
        "    \n",
        "    # Load pre-built index dictionary\n",
        "    # format, for each index in faiss index (key), values are the paper_id, and sentence_id, of the embedded sentence at that index locaiton in the faiss index. \n",
        "\n",
        "    #filepath = Path(\"/kaggle/input/faiss-index-to-doc-sent-ids-dict\") / \"faiss_index_ids_dict_all\"\n",
        "    filepath=\"/content/drive/My Drive/kaggle/covid19/input/faiss_index_ids_dict_all\"\n",
        "\n",
        "    infile=open(filepath, \"rb\")\n",
        "    ids_dict=pickle.load(infile)\n",
        "    \n",
        "    return gpu_index, ids_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "choZcQVCbBcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test \n",
        "gpu_index, ids_dict=read_full_faiss_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IMytNe9SbBcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load pre-trained model from input\n",
        "#model_load_path='/kaggle/input/bertcovidbasicnlists/training_nli_sts_covid-bert-base-2020-04-01_00-26-48'\n",
        "model_load_path='/content/drive/My Drive/kaggle/covid19/input/training_nli_sts_covid-bert-base-2020-04-01_00-26-48'\n",
        "\n",
        "model=torch.load(model_load_path) \n",
        "# type(model) #  model is of type \"SentenceTransformer\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6_8RG9GFbBcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load pre-built files containing dataframes, where each row represents one paper.\n",
        "# Columns are [paper_id, abstract_text, body_text,ents]\n",
        "# The \"ents\" column represents entities present in the abstract (or if not provided, the body text.) \n",
        "# The \"ents\" column was generate using code in Part B, but was run on Google Colab as described below. \n",
        "def read_full_cord19_df():\n",
        "    df_covid1=pd.read_csv(\"/content/1.csv\",index_col=0)\n",
        "    df_covid2=pd.read_csv(\"/content/2.csv\",index_col=0)\n",
        "    df_covid3=pd.read_csv(\"/content/3.csv\",index_col=0)\n",
        "    df_covid4=pd.read_csv(\"/content/4.csv\",index_col=0)\n",
        "    df_covid5=pd.read_csv(\"/content/5.csv\",index_col=0)\n",
        "\n",
        "    # Concatenate individual dfs to one df\n",
        "    df_covid_ents=pd.concat([df_covid1,df_covid2,df_covid3,df_covid4,df_covid5])\n",
        "    return df_covid_ents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uRftDafUbBc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test\n",
        "# ensure that hydrochloroquine in detected in this new dataset, using a known document. \n",
        "df_covid_ents=read_full_cord19_df()\n",
        "\n",
        "# test a known paper_id\n",
        "#df_covid_ents[df_covid_ents['paper_id']==\"50be853b37945ba63f2fa2c4654b8c57ce0c1597\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-9_dnuXpM_d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8d46a34-db0a-4033-9137-685f017df8b7"
      },
      "source": [
        "df_covid_ents.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52100, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "h1xuj_ZNbBc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let us run a test queries\n",
        "query_list=[]\n",
        "query_list.append(\"nurse to patient transmission in aged care facilities\")\n",
        "\n",
        "# create a numpy array, and normalise\n",
        "xq=embed_sentence_list(model,query_list) #model is instantiated previously from sentence-transformers\n",
        "faiss.normalize_L2(xq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AdMwa9HbBc_",
        "colab_type": "text"
      },
      "source": [
        "View top K results\n",
        "\n",
        "top_k \n",
        "- First element is scores, second element is index of match \n",
        "- One row per query, columns are the 1..k'th best match for the query (by cosine similairty)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "q7ydifJKbBdC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2833ac1e-631b-46e0-c576-23500f95bde6"
      },
      "source": [
        "top_k = gpu_index.search(xq[0,:].reshape(1,-1), 3) # sanity check\n",
        "top_k"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.64328206, 0.62654847, 0.62047064]], dtype=float32),\n",
              " array([[120006,  82333,  91320]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wcbGsDX2bBdH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "91a6adfc-366c-4a08-dcfa-ea4259684071"
      },
      "source": [
        "# Examine the first (top) results\n",
        "j=0 # first result\n",
        "\n",
        "#  return faiss index values from matches from second element in result list (at top_k[1]).\n",
        "# Once in list, get first row (query), and j'th column (j'th best match ) (at ...to_list()[0][j])\n",
        "index_tmp=top_k[1].tolist()[0][j] \n",
        "\n",
        "# Retrieve original sentence text from best match \n",
        "paper_id, sent_id=ids_dict[index_tmp][0] # use dictionary to retrieve original paper, and sentence location \n",
        "paper_row=df_covid_ents[df_covid_ents['paper_id']==paper_id] # get row in document by filtering for unique paper id \n",
        "\n",
        "doc=nlp(paper_row.iloc[0]['body_text']) # convert text to sentences \n",
        "\n",
        "\n",
        "# get sentence - need to re-execute spacy pipeline to retrieve sentences since this is not stored. \n",
        "list_of_sents=[sent.text for sent in doc.sents]\n",
        "sent=list_of_sents[sent_id] # retrieve sentence id\n",
        "\n",
        "\n",
        "print(sent)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nurses in the 7th floor who had close contact with MERS patients and showed MERS symptoms were transferred (National medical center, Chungju medical center, Gonju medical center, and Daejeon Army Hospital).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL5JtJYibBdM",
        "colab_type": "text"
      },
      "source": [
        "That's great. But we might need more context to know whether that sentence is relevant to our query. We use spacy spans to grab the context, i.e. text around the sentence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8w4ZS5AibBdN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "e962a7a9-18bf-4509-bd8b-452c97de4771"
      },
      "source": [
        "list_of_spans=[sent for sent in doc.sents]\n",
        "\n",
        "span_start=list_of_spans[sent_id].start\n",
        "span_end=list_of_spans[sent_id].end\n",
        "if span_start < 100:\n",
        "    span_start = 0\n",
        "else:\n",
        "    span_start -=100\n",
        "if (span_end + 100) > len(doc):\n",
        "    span_end = len(doc)\n",
        "else:\n",
        "    span_end += 100\n",
        "    \n",
        "span_results=doc[span_start: span_end]\n",
        "\n",
        "\n",
        "list_of_spans[sent_id] # original sentence \n",
        "span_results # full span "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Nurses in the 7th floor who had close contact with MERS patients and showed MERS symptoms were transferred (National medical center, Chungju medical center, Gonju medical center, and Daejeon Army Hospital)."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ward because of small numbers of admitting rooms. Medical staffs exposed to MERS worked in the cohort area.\n",
              "On the June 18th, a nurse working in the cohort ward was confirmed with MERS due to the 119th patient. RRT recommended emergency room and out-patient clinic be closed after coordinating with hospital officials in order to prepare isolating rooms. Patients in the cohort ward were sent to a single room. Patients who didn`t have close contact on the 5th floor were discharged. Wards on the 3rd floor modified to single isolated room. Nurses in the 7th floor who had close contact with MERS patients and showed MERS symptoms were transferred (National medical center, Chungju medical center, Gonju medical center, and Daejeon Army Hospital). Also Army medical staffs were dispatched due to lack of medical staffs.\n",
              "On June 13th, an information technology (IT) employee who worked at the ' A' hospital (the 143th MERS patient) was identified on the 12th floor. The hospital was closed and the RRT guided isolate all patients on the 11th and 12th floor. Non-contact patients were discharged or transferred to another hospital. Single isolation rooms were prepared on the 11th and 12th floor. Contact medical staffs were quarantined, and the 180th patient was identified 8 days"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkK14WT-bBdW",
        "colab_type": "text"
      },
      "source": [
        "Let's check the score returned by faiss manually. It should be the cosine between the embedded query matrix, and the result vector. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ibVumgHFbBdX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51c6cb2b-68e0-4cd8-dad3-da51903afe13"
      },
      "source": [
        "score_tmp=top_k[0].tolist()[0][j] # return faiss scores from first element in result list (at top_k[0])\n",
        "score_tmp # faiss inner product score\n",
        "\n",
        "# check the score manually, to make sure it is what we expect \n",
        "doc_matrix=embed_sentence_list(model,list_of_sents)\n",
        "faiss.normalize_L2(doc_matrix)\n",
        "from scipy.spatial.distance import cosine\n",
        "1-cosine(xq[0,:],doc_matrix[sent_id,:]) # first query (this is a cosine distance, not a cosine similarity)  # agreement! \n",
        "\n",
        "np.inner(xq[0,:],doc_matrix[sent_id,:]) # agreement! "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6432820558547974"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6432819366455078"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.64328206"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giCVL1EjbBdd",
        "colab_type": "text"
      },
      "source": [
        "Now, we might need to create our own index, based on a limited set of keywords. \n",
        "This is a bit time-consuming, and ideally I would shift this to a GCP VM, with an API where it might run more quickly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kBO9wNutbBdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "\n",
        "def create_gpu_index(df_covid_tmp):\n",
        "    \"\"\" \n",
        "    used to generate a smaller faiss index, limited by keyword\n",
        "    \"\"\"\n",
        "    tqdm.pandas(desc=\"my bar!\")\n",
        "\n",
        "    print(\"creating new gpu index of size\", df_covid_tmp.shape[0])\n",
        "    \n",
        "    # init faiss index\n",
        "    d=768 # sentence transformer embedding length\n",
        "    res = faiss.StandardGpuResources()  # use a single GPU\n",
        "    index = faiss.IndexIDMap(faiss.IndexFlatIP(d)) # IP is inner product. Data must be normalised first\n",
        "    gpu_index_tmp = faiss.index_cpu_to_gpu(res, 0, index)\n",
        "\n",
        "    # init dict\n",
        "    ids_dict_tmp = collections.defaultdict(list)\n",
        "\n",
        "    ids_next=0\n",
        "    i=0\n",
        "    for row in tqdm(range(df_covid_tmp.shape[0])):\n",
        "        doc=nlp(df_covid_tmp.iloc[row]['body_text'])\n",
        "        paper_id=df_covid_tmp.iloc[row]['paper_id']\n",
        "        \n",
        "        list_of_sents=[sent.text for sent in doc.sents]\n",
        "        #if len(list_of_sents) > 800:\n",
        "        #    list_of_sents=list_of_sents[:800] # just taking first 800 sentences for memory reasons. \n",
        "            \n",
        "        doc_matrix=embed_sentence_list(model,list_of_sents)\n",
        "        faiss.normalize_L2(doc_matrix)\n",
        "\n",
        "        # ids in faiss index begin after last idx (last document processed, last sentence)\n",
        "        custom_ids = np.array(range(ids_next, ids_next+len(doc_matrix))) # from last postion (range add +1) to new position\n",
        "        ids_next=ids_next+len(doc_matrix) # increment by current document length. Current doc lenght = num sentences in current doc             \n",
        "        gpu_index_tmp.add_with_ids(doc_matrix, custom_ids)\n",
        "        for sent_idx, faiss_ids_val in enumerate(custom_ids): # sentence_idx is sentence id within the 1 document, faiss_ids_val is the faiss index value\n",
        "            items=(paper_id, sent_idx)\n",
        "            ids_dict_tmp[faiss_ids_val].append(items)\n",
        "            \n",
        "    del doc_matrix\n",
        "    del doc\n",
        "    gc.collect()\n",
        "    return(gpu_index_tmp,ids_dict_tmp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "f87pRaE-bBdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to  do - add in function to process search response\n",
        "# combine with absolute match result to ensure sentence contain keywords\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "import gc\n",
        "def search(model,query, k=3, gpu_index_default=None,ids_dict_default=None,keyword=None,df_covid_ents_default=None):\n",
        "    \"\"\"\n",
        "    returns results based on keyword, the gpu_index, and the ids_dict\n",
        "    \n",
        "    :param model, query, k, keyword, gpu_index_default, ids_dict_default \n",
        "    :type\n",
        "    :param query\n",
        "    :type \n",
        "    \"\"\"\n",
        "         \n",
        "    query_list=[query]\n",
        "    xq=embed_sentence_list(model,query_list) # model is instantiated previously from sentence-transformers\n",
        "    faiss.normalize_L2(xq)\n",
        "\n",
        "    if df_covid_ents_default is None:\n",
        "      df_covid_ents=read_full_cord19_df() #df_covid_ents\n",
        "    else:\n",
        "      df_covid_ents=df_covid_ents_default\n",
        "\n",
        "    if gpu_index_default==None or ids_dict_default==None:\n",
        "\n",
        "      if keyword is not None:\n",
        "        df_covid_tmp=df_covid_ents[df_covid_ents['ents'].str.contains(keyword, na=False) ].copy() # filter on keyword\n",
        "        print(\"Create new faiss index based on\", df_covid_tmp.shape[0], \"documents\")\n",
        "        gpu_index_tmp,ids_dict_tmp = create_gpu_index(df_covid_tmp)  # generate new index, based on filtered dataframe\n",
        "\n",
        "      else: # no keyword but still need to create index from scratch\n",
        "        gpu_index_tmp, ids_dict_tmp = read_full_faiss_index() #gpu_index_default # if no keyword, use original artifacts\n",
        "        df_covid_tmp=df_covid_ents #df_covid_ents\n",
        "\n",
        "    else: \n",
        "        print(\"using custom index and dict - ignoring any keywords\") #ignore keyword\n",
        "        gpu_index_tmp=gpu_index_default\n",
        "        ids_dict_tmp=ids_dict_default\n",
        "        df_covid_tmp=df_covid_ents\n",
        "  \n",
        "    # get top k best matches through index look_up\n",
        "    top_k = gpu_index_tmp.search(xq, k)  \n",
        "    # >>>\n",
        "    pp.pprint(\"end faiss search\")\n",
        "    # >>>\n",
        "      \n",
        "    # init output results dataframe \n",
        "    colnames=[\"query\",\"sentence\",\"score\", \"span\",\"paper_id\"]    \n",
        "    results=pd.DataFrame(columns=colnames)\n",
        "      \n",
        "    for i, _id in tqdm(enumerate(top_k[1].tolist()[0])): # for each result in the top k, element zero since only one query (could do batch queries)\n",
        "        paper_id, sent_id=ids_dict_tmp[_id][0]\n",
        "          \n",
        "        ## retrieve sent value   \n",
        "        # get row in document by filtering for unique paper id \n",
        "        paper_row=df_covid_tmp[df_covid_tmp['paper_id']==paper_id]\n",
        "        \n",
        "        # convert text to sentences \n",
        "        doc=nlp(paper_row.iloc[0]['body_text'])\n",
        "\n",
        "        # get sentence - need to re-execute spacy pipeline to retrieve sentences since this is not stored. \n",
        "        list_of_sents=[sent.text for sent in doc.sents]\n",
        "        sentence_result=list_of_sents[sent_id] # retrieve original sentence text       \n",
        "\n",
        "        # retrieve spans\n",
        "        list_of_spans=[sent for sent in doc.sents]\n",
        "        \n",
        "        span_start=list_of_spans[sent_id].start\n",
        "        span_end=list_of_spans[sent_id].end\n",
        "\n",
        "        if span_start < 100:\n",
        "          span_start = 0\n",
        "        else:\n",
        "          span_start -= 100\n",
        "                \n",
        "        if (span_end + 100) > len(doc):\n",
        "          span_end = len(doc)\n",
        "        else:\n",
        "          span_end += 100\n",
        "                \n",
        "        span_results=doc[span_start: span_end]        \n",
        "\n",
        "        # get score\n",
        "        score_tmp=top_k[0].tolist()[0][i] # score for i'th match\n",
        "            \n",
        "        #title=paper_row['title'] # to do\n",
        "        #authors=paper_row['authors'] # to \n",
        "        #abstract=paper_row['abstract'] # to do\n",
        "            \n",
        "        tmp=pd.DataFrame( [pd.Series([query,sentence_result, score_tmp, span_results, paper_id],index=colnames)] )\n",
        "        results=results.append(tmp, ignore_index=True, sort=False)\n",
        "              \n",
        "    return(results, gpu_index_tmp, ids_dict_tmp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "id": "0vZiHJvbbBdr",
        "colab_type": "text"
      },
      "source": [
        "#### Example Simple Semantic Search \n",
        "Lets look for examples of nurses transmitting to patients in hospitals. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IvMXYj8WbBds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b4047782-3f34-4154-9760-3778cdb06c05"
      },
      "source": [
        "results=search(model=model,\n",
        "               query=\"nurses transmit to patients in hospitals\", \n",
        "               k=6)\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "'end faiss search'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6it [00:03,  1.92it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DYJndAxtbBd6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "outputId": "bf35518d-6a4e-4b79-8c91-c4977c14c13a"
      },
      "source": [
        "df,index_,dict_=results\n",
        "df[[\"paper_id\",\"sentence\",\"score\",\"span\"]].head() ## the same contaent appears in two separate papers. Note sure why"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>score</th>\n",
              "      <th>span</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1b44eb4e309e0a843a7c308eeddab0e852704a19</td>\n",
              "      <td>First, nurses come in contact with their patients more frequently than doctors while performing their basic nursing and life care tasks.</td>\n",
              "      <td>0.762037</td>\n",
              "      <td>(., Therefore, ,, examining, the, PTSD, symptoms, of, these, medical, workers, must, be, prioritized, ., Exposure, to, traumatic, events, is, the, immediate, cause, of, PTSD, and, is, essential, in, diagnosing, such, disorder, ., Poton, [, 16, ], found, that, medical, workers, usually, manifest, the, symptoms, of, their, patients, after, experiencing, a, traumatic, event, ,, but, such, symptoms, were, always, ignored, ., Alexander, [, 17, ], suggested, that, those, people, who, were, repeatedly, exposed, to, traumatic, events, were, prone, to, suffering, all, kinds, of, psychological, problems, ., \\n, The, nurses, obtained, higher, PCL-C, scores, than, the, doctors, for, several, reasons, ., ...)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f79cb6c46151a0af6270805ed459f6e9bc95e031</td>\n",
              "      <td>First, nurses come in contact with their patients more frequently than doctors while performing their basic nursing and life care tasks.</td>\n",
              "      <td>0.762037</td>\n",
              "      <td>(., Therefore, ,, examining, the, PTSD, symptoms, of, these, medical, workers, must, be, prioritized, ., Exposure, to, traumatic, events, is, the, immediate, cause, of, PTSD, and, is, essential, in, diagnosing, such, disorder, ., Poton, [, 16, ], found, that, medical, workers, usually, manifest, the, symptoms, of, their, patients, after, experiencing, a, traumatic, event, ,, but, such, symptoms, were, always, ignored, ., Alexander, [, 17, ], suggested, that, those, people, who, were, repeatedly, exposed, to, traumatic, events, were, prone, to, suffering, all, kinds, of, psychological, problems, ., \\n, The, nurses, obtained, higher, PCL-C, scores, than, the, doctors, for, several, reasons, ., ...)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>954d000b2e7252ffb05812341a6436d3d784494a</td>\n",
              "      <td>Nurses in the 7th floor who had close contact with MERS patients and showed MERS symptoms were transferred (National medical center, Chungju medical center, Gonju medical center, and Daejeon Army Hospital).</td>\n",
              "      <td>0.739247</td>\n",
              "      <td>(ward, because, of, small, numbers, of, admitting, rooms, ., Medical, staffs, exposed, to, MERS, worked, in, the, cohort, area, ., \\n, On, the, June, 18th, ,, a, nurse, working, in, the, cohort, ward, was, confirmed, with, MERS, due, to, the, 119th, patient, ., RRT, recommended, emergency, room, and, out-patient, clinic, be, closed, after, coordinating, with, hospital, officials, in, order, to, prepare, isolating, rooms, ., Patients, in, the, cohort, ward, were, sent, to, a, single, room, ., Patients, who, didn`t, have, close, contact, on, the, 5th, floor, were, discharged, ., Wards, on, the, 3rd, floor, modified, to, single, isolated, room, ., ...)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>98e23bb77cb986fe21f095253af64843d3f4e8cc</td>\n",
              "      <td>Recognized cases occurred predominantly among staff in hospitals and nursing homes.</td>\n",
              "      <td>0.723472</td>\n",
              "      <td>(to, HCWs, (, 6, cases, ), ,, and, from, HCWs, to, their, household, contacts, (, 1, case, ), ., Five, out, of, six, occupational, cases, of, ebola, hemorrhagic, fever, occurred, in, HCWs, [, 27, ], ., \\n, An, immunocompetent, HCW, with, no, known, history, of, varicellazoster, virus, disease, was, exposed, to, a, patient, with, herpes, zoster, and, was, immunized, 2, days, later, ., Twenty-seven, days, after, receiving, the, varicella, vaccine, ,, while, hospitalized, ,, she, developed, a, disseminated, rash, [, 28, ], ., Occupationally, acquired, infection, with, methicillin-resistant, Staphylococcus, aureus, (, MRSA, ), is, an, issue, of, increasing, concern, ., ...)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0573f2143ac48f91fc247c875388e55d8576bcab</td>\n",
              "      <td>Recognized cases occurred predominantly among staff in hospitals and nursing homes.</td>\n",
              "      <td>0.723472</td>\n",
              "      <td>(to, HCWs, (, 6, cases, ), ,, and, from, HCWs, to, their, household, contacts, (, 1, case, ), ., Five, out, of, six, occupational, cases, of, ebola, hemorrhagic, fever, occurred, in, HCWs, [, 27, ], ., \\n, An, immunocompetent, HCW, with, no, known, history, of, varicellazoster, virus, disease, was, exposed, to, a, patient, with, herpes, zoster, and, was, immunized, 2, days, later, ., Twenty-seven, days, after, receiving, the, varicella, vaccine, ,, while, hospitalized, ,, she, developed, a, disseminated, rash, [, 28, ], ., Occupationally, acquired, infection, with, methicillin-resistant, Staphylococcus, aureus, (, MRSA, ), is, an, issue, of, increasing, concern, ., ...)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   paper_id                                                                                                                                                                                                        sentence     score                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               span\n",
              "0  1b44eb4e309e0a843a7c308eeddab0e852704a19  First, nurses come in contact with their patients more frequently than doctors while performing their basic nursing and life care tasks.                                                                        0.762037  (., Therefore, ,, examining, the, PTSD, symptoms, of, these, medical, workers, must, be, prioritized, ., Exposure, to, traumatic, events, is, the, immediate, cause, of, PTSD, and, is, essential, in, diagnosing, such, disorder, ., Poton, [, 16, ], found, that, medical, workers, usually, manifest, the, symptoms, of, their, patients, after, experiencing, a, traumatic, event, ,, but, such, symptoms, were, always, ignored, ., Alexander, [, 17, ], suggested, that, those, people, who, were, repeatedly, exposed, to, traumatic, events, were, prone, to, suffering, all, kinds, of, psychological, problems, ., \\n, The, nurses, obtained, higher, PCL-C, scores, than, the, doctors, for, several, reasons, ., ...)\n",
              "1  f79cb6c46151a0af6270805ed459f6e9bc95e031  First, nurses come in contact with their patients more frequently than doctors while performing their basic nursing and life care tasks.                                                                        0.762037  (., Therefore, ,, examining, the, PTSD, symptoms, of, these, medical, workers, must, be, prioritized, ., Exposure, to, traumatic, events, is, the, immediate, cause, of, PTSD, and, is, essential, in, diagnosing, such, disorder, ., Poton, [, 16, ], found, that, medical, workers, usually, manifest, the, symptoms, of, their, patients, after, experiencing, a, traumatic, event, ,, but, such, symptoms, were, always, ignored, ., Alexander, [, 17, ], suggested, that, those, people, who, were, repeatedly, exposed, to, traumatic, events, were, prone, to, suffering, all, kinds, of, psychological, problems, ., \\n, The, nurses, obtained, higher, PCL-C, scores, than, the, doctors, for, several, reasons, ., ...)\n",
              "2  954d000b2e7252ffb05812341a6436d3d784494a  Nurses in the 7th floor who had close contact with MERS patients and showed MERS symptoms were transferred (National medical center, Chungju medical center, Gonju medical center, and Daejeon Army Hospital).  0.739247  (ward, because, of, small, numbers, of, admitting, rooms, ., Medical, staffs, exposed, to, MERS, worked, in, the, cohort, area, ., \\n, On, the, June, 18th, ,, a, nurse, working, in, the, cohort, ward, was, confirmed, with, MERS, due, to, the, 119th, patient, ., RRT, recommended, emergency, room, and, out-patient, clinic, be, closed, after, coordinating, with, hospital, officials, in, order, to, prepare, isolating, rooms, ., Patients, in, the, cohort, ward, were, sent, to, a, single, room, ., Patients, who, didn`t, have, close, contact, on, the, 5th, floor, were, discharged, ., Wards, on, the, 3rd, floor, modified, to, single, isolated, room, ., ...)                                                \n",
              "3  98e23bb77cb986fe21f095253af64843d3f4e8cc  Recognized cases occurred predominantly among staff in hospitals and nursing homes.                                                                                                                             0.723472  (to, HCWs, (, 6, cases, ), ,, and, from, HCWs, to, their, household, contacts, (, 1, case, ), ., Five, out, of, six, occupational, cases, of, ebola, hemorrhagic, fever, occurred, in, HCWs, [, 27, ], ., \\n, An, immunocompetent, HCW, with, no, known, history, of, varicellazoster, virus, disease, was, exposed, to, a, patient, with, herpes, zoster, and, was, immunized, 2, days, later, ., Twenty-seven, days, after, receiving, the, varicella, vaccine, ,, while, hospitalized, ,, she, developed, a, disseminated, rash, [, 28, ], ., Occupationally, acquired, infection, with, methicillin-resistant, Staphylococcus, aureus, (, MRSA, ), is, an, issue, of, increasing, concern, ., ...)                           \n",
              "4  0573f2143ac48f91fc247c875388e55d8576bcab  Recognized cases occurred predominantly among staff in hospitals and nursing homes.                                                                                                                             0.723472  (to, HCWs, (, 6, cases, ), ,, and, from, HCWs, to, their, household, contacts, (, 1, case, ), ., Five, out, of, six, occupational, cases, of, ebola, hemorrhagic, fever, occurred, in, HCWs, [, 27, ], ., \\n, An, immunocompetent, HCW, with, no, known, history, of, varicellazoster, virus, disease, was, exposed, to, a, patient, with, herpes, zoster, and, was, immunized, 2, days, later, ., Twenty-seven, days, after, receiving, the, varicella, vaccine, ,, while, hospitalized, ,, she, developed, a, disseminated, rash, [, 28, ], ., Occupationally, acquired, infection, with, methicillin-resistant, Staphylococcus, aureus, (, MRSA, ), is, an, issue, of, increasing, concern, ., ...)                           "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tUL6bECrbBeA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "600e595e-6a37-425a-9c89-359a23463c4d"
      },
      "source": [
        "del gpu_index\n",
        "del ids_dict\n",
        "#del df_covid_ents \n",
        "gc.collect()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GUs9LynrbBeF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "7a86ce4b-a491-481f-8a7c-829946820191"
      },
      "source": [
        "#results=search(model=model,\n",
        "#               query=\"Hydroxychloroquine (an analogue of chloroquine) has been demonstrated to have an anti-SARS-CoV activity in vitro [12] \",\n",
        "#               k=3, \n",
        "#               gpu_index_default=None, \n",
        "#               ids_dict_default=None,\n",
        "#             keyword=\"hydroxychloroquine\", \n",
        "#)\n",
        "\n",
        "results=search(model=model,\n",
        "               query=\"timing intervals of treatment delivered\",\n",
        "               k=3, \n",
        "               gpu_index_default=None, \n",
        "               ids_dict_default=None,\n",
        "             keyword=\"hydroxychloroquine\", \n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create new faiss index based on 78 documents\n",
            "creating new gpu index of size 78\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 78/78 [12:14<00:00,  9.42s/it]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "'end faiss search'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3it [05:19, 106.41s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8Mw6RSVCbBeK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "730ef2ae-df0c-4c2b-a1ff-5a02db1aa323"
      },
      "source": [
        "df_results_hcq, gcu_index_hcq, ids_dict_hcq=results\n",
        "df_results_hcq[['paper_id','sentence','score','span']]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>score</th>\n",
              "      <th>span</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PMC3654146</td>\n",
              "      <td>Prognosis depends on timing of institution of therapy.\\n</td>\n",
              "      <td>0.840111</td>\n",
              "      <td>(Moderate, to, severe, episode, which, our, patient, had, is, defined, as, involvement, of, at, least, two, or, more, lobes, along, with, decreased, oxygen, saturation, require, full, red-cell, exchange, transfusion, ., Goal, is, to, reduce, hemoglobin, S, to, less, than, 30, %, while, keeping, hemoglobin, to, less, than, 10, gm/dl, ., Full, exchange, transfusion, appears, to, be, more, iron-neutral, than, partial, exchange, transfusion, ., Exchange, transfusion, can, be, performed, manually, or, by, apheresis, machine, ., Third, generation, cephalosporin, and, a, macrolide, can, be, safely, used, in, pregnancy, to, cover, for, atypical, bacteria, as, well, as, streptococcus, pneumonia, and, hemophilus, influenzae, ., ...)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PMC4429500</td>\n",
              "      <td>Interval between discharge and the follow up visit were calculated.</td>\n",
              "      <td>0.701133</td>\n",
              "      <td>(study, period, ,, and, who, saw, their, PCP, for, follow, up, ., \\n, METHODS, :, WCIMA, is, a, large, internal, medicine, practice, affiliated, with, Weill, Cornell, Medical, College, in, New, York, City, ., It, is, the, main, practice, site, for, 33, faculty, physicians, and, 136, internal, medicine, residents, ., Through, data, extraction, of, our, electronic, health, records, ,, we, identified, all, WCIMA, discharges, from, NYP/WCMC, from, 9/1/2013, to, 10/12/2013, ., Information, for, each, discharge, including, basic, patient, identifiers, ,, age, ,, payer, ,, hospital, department/, service, ,, assigned, primary, care, provider, ,, completed, visit, date, and, provider, were, obtained, ., ...)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PMC4429500</td>\n",
              "      <td>We stratified analyses for each intervention category by outcome timing.</td>\n",
              "      <td>0.692260</td>\n",
              "      <td>(), ,, home, visits, ,, telemonitoring, ,, telephone, support, ,, or, interventions, to, increase, provider, continuity, ., We, required, studies, to, report, a, readmission, rate, ,, mortality, rate, ,, or, the, composite, outcome, (, all-cause, readmission, or, mortality, ), ., We, included, outcomes, occurring, no, longer, than, 6, months, following, an, index, hospitalization, ., Two, investigators, independently, selected, ,, extracted, data, from, ,, and, rated, risk, of, bias, of, included, studies, ., We, grouped, studies, of, similar, interventions, for, our, evidence, synthesis, based, on, the, mode, and, environment, of, delivery, ., We, used, random-effects, models, to, estimate, pooled, effects, ., ...)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     paper_id                                                                  sentence     score                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          span\n",
              "0  PMC3654146  Prognosis depends on timing of institution of therapy.\\n                  0.840111  (Moderate, to, severe, episode, which, our, patient, had, is, defined, as, involvement, of, at, least, two, or, more, lobes, along, with, decreased, oxygen, saturation, require, full, red-cell, exchange, transfusion, ., Goal, is, to, reduce, hemoglobin, S, to, less, than, 30, %, while, keeping, hemoglobin, to, less, than, 10, gm/dl, ., Full, exchange, transfusion, appears, to, be, more, iron-neutral, than, partial, exchange, transfusion, ., Exchange, transfusion, can, be, performed, manually, or, by, apheresis, machine, ., Third, generation, cephalosporin, and, a, macrolide, can, be, safely, used, in, pregnancy, to, cover, for, atypical, bacteria, as, well, as, streptococcus, pneumonia, and, hemophilus, influenzae, ., ...)\n",
              "1  PMC4429500  Interval between discharge and the follow up visit were calculated.       0.701133  (study, period, ,, and, who, saw, their, PCP, for, follow, up, ., \\n, METHODS, :, WCIMA, is, a, large, internal, medicine, practice, affiliated, with, Weill, Cornell, Medical, College, in, New, York, City, ., It, is, the, main, practice, site, for, 33, faculty, physicians, and, 136, internal, medicine, residents, ., Through, data, extraction, of, our, electronic, health, records, ,, we, identified, all, WCIMA, discharges, from, NYP/WCMC, from, 9/1/2013, to, 10/12/2013, ., Information, for, each, discharge, including, basic, patient, identifiers, ,, age, ,, payer, ,, hospital, department/, service, ,, assigned, primary, care, provider, ,, completed, visit, date, and, provider, were, obtained, ., ...)                        \n",
              "2  PMC4429500  We stratified analyses for each intervention category by outcome timing.  0.692260  (), ,, home, visits, ,, telemonitoring, ,, telephone, support, ,, or, interventions, to, increase, provider, continuity, ., We, required, studies, to, report, a, readmission, rate, ,, mortality, rate, ,, or, the, composite, outcome, (, all-cause, readmission, or, mortality, ), ., We, included, outcomes, occurring, no, longer, than, 6, months, following, an, index, hospitalization, ., Two, investigators, independently, selected, ,, extracted, data, from, ,, and, rated, risk, of, bias, of, included, studies, ., We, grouped, studies, of, similar, interventions, for, our, evidence, synthesis, based, on, the, mode, and, environment, of, delivery, ., We, used, random-effects, models, to, estimate, pooled, effects, ., ...)       "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eeeo2ZlZyJD3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5122df08-4088-46d1-92dd-0f322ec101ce"
      },
      "source": [
        "results=search(model=model,\n",
        "               query=\"the treatment was delivered at timing intervals \",\n",
        "               k=3, \n",
        "               gpu_index_default=gcu_index_hcq, \n",
        "               ids_dict_default=ids_dict_hcq,\n",
        "               keyword=None, df_covid_ents_default=df_covid_ents\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "using custom index and dict - ignoring any keywords\n",
            "'end faiss search'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [01:39, 99.25s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psA-hgTw5VLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "4b167464-7e4f-4be4-e9c6-0acc864f613f"
      },
      "source": [
        "type(results)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-867f27eb9551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu2bkyiM4jvY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "b66ec36a-3928-4e28-f3d2-eef2557b3222"
      },
      "source": [
        "df_results_hcq_timing, _, _ = results\n",
        "df_results_hcq_timing[['paper_id','sentence','score','span']]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4acea9f95c87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_results_hcq_timing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_results_hcq_timing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paper_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z-QhyMVbBeN",
        "colab_type": "text"
      },
      "source": [
        "### Part A - SentenceTransformer model fine-tuning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pNZImS9IbBeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import sentence_transformer functions \n",
        "# See fine-tuning example at - https://github.com/UKPLab/sentence-transformers/blob/master/examples/training_nli_bert.py\n",
        "os.chdir(\"/kaggle/working/sentence-transformers\")\n",
        "\n",
        "from sentence_transformers import models, losses\n",
        "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer\n",
        "from sentence_transformers.readers import *\n",
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "from sentence_transformers.datasets import *\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "import logging\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "id": "60RIwW-TbBeR",
        "colab_type": "text"
      },
      "source": [
        "Deepset have finetuned a BERT language model on the CORD-19 dataset (see references above). \n",
        "\n",
        "https://huggingface.co/deepset/covid_bert_base\n",
        "\n",
        "We load this model. \n",
        "The following code is otherwise lifted from \"https://github.com/UKPLab/sentence-transformers/blob/master/examples/training_nli_bert.py\" to complete the remainder of the fine-tuning. \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4jGjQ4lybBeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up SentenceTransformer model, using pooled averaging. \n",
        "# start with covid_bert_base model, rather than CORD-19 task\n",
        "\n",
        "word_embedding_model = models.BERT(\"deepset/covid_bert_base\")\n",
        "\n",
        "# Apply mean pooling to get one fixed sized sentence vector\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
        "                               pooling_mode_mean_tokens=True,\n",
        "                               pooling_mode_cls_token=False,\n",
        "                               pooling_mode_max_tokens=False)\n",
        "\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7xdOeIeBbBeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now fine-tune model further on NLI and STS tasks to get natural language and semantic tones included in embeddings\n",
        "\n",
        "!python examples/datasets/get_data.py # downloads AllNLI.zip and STSbenchmark.zip datasets "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JRHfckTvbBeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"./examples\") # switch to examples directory where output is stored\n",
        "nli_reader = NLIDataReader('datasets/AllNLI')\n",
        "train_data = SentencesDataset(nli_reader.get_examples('train.gz'), model=model)\n",
        "model_name = 'covid-bert-base'\n",
        "batch_size = 16\n",
        "nli_reader = NLIDataReader('datasets/AllNLI')\n",
        "sts_reader = STSDataReader('datasets/stsbenchmark')\n",
        "train_num_labels = nli_reader.get_num_labels()\n",
        "model_save_path = 'kaggle/working/training_nli_'+model_name+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "train_loss = losses.SoftmaxLoss(model=model, sentence_embedding_dimension=model.get_sentence_embedding_dimension(), num_labels=train_num_labels)\n",
        "\n",
        "logging.info(\"Read STSbenchmark dev dataset\")\n",
        "dev_data = SentencesDataset(examples=sts_reader.get_examples('sts-dev.csv'), model=model)\n",
        "dev_dataloader = DataLoader(dev_data, shuffle=False, batch_size=batch_size)\n",
        "evaluator = EmbeddingSimilarityEvaluator(dev_dataloader)\n",
        "\n",
        "# Configure the training\n",
        "num_epochs = 1\n",
        "\n",
        "warmup_steps = math.ceil(len(train_dataloader) * num_epochs / batch_size * 0.1) #10% of train data for warm-up\n",
        "logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
        "          evaluator=evaluator,\n",
        "          epochs=num_epochs,\n",
        "          evaluation_steps=1000,\n",
        "          warmup_steps=warmup_steps,\n",
        "          output_path=model_save_path\n",
        "          )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fCozyCjSbBea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model \n",
        "model_save_name='training_nli_covid_'+model_name+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "filename=Path(\"/kaggle/working/\" ) / model_save_name \n",
        "outfile = open(filename,'wb')\n",
        "torch.save(model, outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC-O9ZqibBed",
        "colab_type": "text"
      },
      "source": [
        "### Part B - Create df_covid \n",
        "\n",
        "This part is divided into Part B.1 and Part B.2\n",
        "\n",
        "Part B.1 is run on Kaggle kernel. It generates a dataframe with columns paper_id, abstract and body_text.\n",
        "\n",
        "Part B.2 was run on Google Colab, which connects to a GCP VM, with 16 cores to allow efficient multiprocessing of dataframe batches. . I included the code here to view. This part takes the dataframe from B.1, and uses scispacy to extract scientific entities, and creates a new column \"ents\" in the dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-dc4oHNDbBee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.kaggle.com/ivanegapratama/covid-eda-initial-exploration-tool\n",
        "# papers_df only got stuff from biox...\n",
        "# we need to get the full data set \n",
        "\n",
        "#https://www.kaggle.com/ivanegapratama/covid-eda-initial-exploration-tool\n",
        "    \n",
        "#import matplotlib.pyplot as plt\n",
        "#plt.style.use('ggplot')\n",
        "import glob\n",
        "import json\n",
        "\n",
        "root_path = '/kaggle/input/CORD-19-research-challenge'\n",
        "metadata_path = f'{root_path}/metadata.csv'\n",
        "meta_df = pd.read_csv(metadata_path, dtype={\n",
        "    'pubmed_id': str,\n",
        "    'Microsoft Academic Paper ID': str, \n",
        "    'doi': str\n",
        "})\n",
        "#meta_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "grbZubG2bBeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_json = glob.glob(f'{root_path}/**/*.json', recursive=True)\n",
        "len(all_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nzwau0UrbBej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FileReader:\n",
        "    def __init__(self, file_path):\n",
        "        with open(file_path) as file:\n",
        "            content = json.load(file)\n",
        "            self.paper_id = content['paper_id']\n",
        "            self.abstract = []\n",
        "            self.body_text = []\n",
        "            # Abstract\n",
        "            if 'abstract' in content.keys():\n",
        "                for entry in content['abstract']:\n",
        "                    self.abstract.append(entry['text'])\n",
        "            else:\n",
        "                self.abstract.append('')\n",
        "            # Body text\n",
        "            if 'body_text' in content.keys():\n",
        "                for entry in content['body_text']:\n",
        "                    self.body_text.append(entry['text'])\n",
        "            else:\n",
        "                self.body_text.append('')\n",
        "                \n",
        "            self.abstract = '\\n'.join(self.abstract)\n",
        "            self.body_text = '\\n'.join(self.body_text)\n",
        "\n",
        "            # Extend Here\n",
        "            #\n",
        "            #\n",
        "    def __repr__(self):\n",
        "        return f'{self.paper_id}: {self.abstract[:200]}... {self.body_text[:200]}...'\n",
        "first_row = FileReader(all_json[0])\n",
        "print(first_row)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y4A2PuF9bBen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_ = {'paper_id': [], 'abstract': [], 'body_text': []}\n",
        "for idx, entry in enumerate(all_json):\n",
        "    if idx % (len(all_json) // 10) == 0:\n",
        "        print(f'Processing index: {idx} of {len(all_json)}')\n",
        "    content = FileReader(entry)\n",
        "    dict_['paper_id'].append(content.paper_id)\n",
        "    dict_['abstract'].append(content.abstract)\n",
        "    dict_['body_text'].append(content.body_text)\n",
        "df_covid = pd.DataFrame(dict_, columns=['paper_id', 'abstract', 'body_text'])\n",
        "#df_covid.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YSUB6oWPbBep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.kaggle.com/maksimeren/covid-19-literature-clustering\n",
        "\n",
        "dict_ = {'paper_id': [], 'abstract': [], 'body_text': [], 'authors': [], 'title': [], 'journal': [], 'abstract_summary': []}\n",
        "for idx, entry in enumerate(all_json):\n",
        "    if idx % (len(all_json) // 10) == 0:\n",
        "        print(f'Processing index: {idx} of {len(all_json)}')\n",
        "    content = FileReader(entry)\n",
        "    \n",
        "    # get metadata information\n",
        "    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n",
        "    # no metadata, skip this paper\n",
        "    if len(meta_data) == 0:\n",
        "        continue\n",
        "    \n",
        "    dict_['paper_id'].append(content.paper_id)\n",
        "    dict_['abstract'].append(content.abstract)\n",
        "    dict_['body_text'].append(content.body_text)\n",
        "    \n",
        "    # also create a column for the summary of abstract to be used in a plot\n",
        "    if len(content.abstract) == 0: \n",
        "        # no abstract provided\n",
        "        dict_['abstract_summary'].append(\"Not provided.\")\n",
        "    elif len(content.abstract.split(' ')) > 100:\n",
        "        # abstract provided is too long for plot, take first 300 words append with ...\n",
        "        info = content.abstract.split(' ')[:100]\n",
        "        summary = get_breaks(' '.join(info), 40)\n",
        "        dict_['abstract_summary'].append(summary + \"...\")\n",
        "    else:\n",
        "        # abstract is short enough\n",
        "        summary = get_breaks(content.abstract, 40)\n",
        "        dict_['abstract_summary'].append(summary)\n",
        "        \n",
        "    # get metadata information\n",
        "    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n",
        "    \n",
        "    try:\n",
        "        # if more than one author\n",
        "        authors = meta_data['authors'].values[0].split(';')\n",
        "        if len(authors) > 2:\n",
        "            # more than 2 authors, may be problem when plotting, so take first 2 append with ...\n",
        "            dict_['authors'].append(\". \".join(authors[:2]) + \"...\")\n",
        "        else:\n",
        "            # authors will fit in plot\n",
        "            dict_['authors'].append(\". \".join(authors))\n",
        "    except Exception as e:\n",
        "        # if only one author - or Null valie\n",
        "        dict_['authors'].append(meta_data['authors'].values[0])\n",
        "    \n",
        "    # add the title information, add breaks when needed\n",
        "    try:\n",
        "        title = get_breaks(meta_data['title'].values[0], 40)\n",
        "        dict_['title'].append(title)\n",
        "    # if title was not provided\n",
        "    except Exception as e:\n",
        "        dict_['title'].append(meta_data['title'].values[0])\n",
        "    \n",
        "    # add the journal information\n",
        "    dict_['journal'].append(meta_data['journal'].values[0])\n",
        "    \n",
        "df_covid = pd.DataFrame(dict_, columns=['paper_id', 'abstract', 'body_text', 'authors', 'title', 'journal', 'abstract_summary'])\n",
        "df_covid.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tRW_vcCibBeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_covid1=df_covid.drop( [\"ents\"],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2Kvszt3sbBew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export index\n",
        "from pathlib import Path\n",
        "filepath = Path(\"/kaggle/working\") /\"df_covid\"\n",
        "outfile=open(filepath, \"wb\")\n",
        "pickle.dump(df_covid,outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "juPq4a10bBez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download model. Upload to datasets\n",
        "os.chdir(\"/kaggle/working\")\n",
        "from IPython.display import FileLink\n",
        "FileLink(r'df_covid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg2v8UyqbBe2",
        "colab_type": "text"
      },
      "source": [
        "### Part C\n",
        "Part C involves embedding the CORD-19 dataset using our fine-tuned SentenceTranformer model (from Part A), and setting up the faiss  index to store the embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "S1a8uwPDbBe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/kaggle/working/sentence-transformers\")\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "os.chdir(\"/kaggle/working/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sDlbxDFsbBe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load model from input \n",
        "model_load_path='/kaggle/input/bertcovidbasicnlists/training_nli_sts_covid-bert-base-2020-04-01_00-26-48'\n",
        "model=torch.load(model_load_path) \n",
        "# type(model) #  model is of type \"SentenceTransformer\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-1p2Pl4tbBe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# init faiss index\n",
        "import faiss # in case not already loaded \n",
        "d=768 # sentence transformer embedding length\n",
        "res = faiss.StandardGpuResources()  # use a single GPU\n",
        "index = faiss.IndexIDMap(faiss.IndexFlatIP(d)) # IP is inner product. Data must be normalised first\n",
        "gpu_index = faiss.index_cpu_to_gpu(res, 0, index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vPzsGvzbbBfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load covid_df\n",
        "# import dictionary\n",
        "from pathlib import Path\n",
        "filepath = Path(\"/kaggle/input/covid-docs-processed-dataframe\") / \"df_covid_ents\"\n",
        "infile=open(filepath, \"rb\")\n",
        "df_covid=pickle.load(infile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3khhYBMbbBfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_covid.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VcDYDam8bBfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed documents and add them to faiss index \n",
        "# maintain a dictionary which stores, for each index in faiss, details of the paper (from papers_df)\n",
        "\n",
        "# index - ids, paper_id, sent_idx\n",
        "\n",
        "ids_dict = collections.defaultdict(list)\n",
        "\n",
        "ids_next=0\n",
        "\n",
        "#for row in range(papers_df.shape[0]):\n",
        "for row in range(df_covid.shape[0]):\n",
        "\n",
        "    # doc=nlp(papers_df.iloc[row]['text'])\n",
        "    doc=nlp(df_covid.iloc[row]['body_text'])\n",
        "\n",
        "    # paper_id=papers_df.iloc[row]['paper_id']\n",
        "    paper_id=df_covid.iloc[row]['paper_id']\n",
        "\n",
        "    list_of_sents=[sent.text for sent in doc.sents]\n",
        "    doc_matrix=embed_sentence_list(model,list_of_sents)\n",
        "    faiss.normalize_L2(doc_matrix)\n",
        "\n",
        "    # ids in faiss index begin after last idx (last document processed, last sentence)\n",
        "    custom_ids = np.array(range(ids_next, ids_next+len(doc_matrix))) # from last postion (range add +1) to new position\n",
        "    ids_next=ids_next+len(doc_matrix) # increment by current document length. Current doc lenght = num sentences in current doc             \n",
        "    gpu_index.add_with_ids(doc_matrix, custom_ids)\n",
        "    for sent_idx, faiss_ids_val in enumerate(custom_ids): # sentence_idx is sentence id within the 1 document, faiss_ids_val is the faiss index value\n",
        "        items=(paper_id, sent_idx)\n",
        "        ids_dict[faiss_ids_val].append(items)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WhdnCn_DbBfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WfeXavktbBfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# serialize index for output \n",
        "cpu_index=faiss.index_gpu_to_cpu(gpu_index)\n",
        "index_ser=serialize_index(cpu_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "z_E7r9akbBfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export index\n",
        "from pathlib import Path\n",
        "filepath = Path(\"/kaggle/working\") /\"index_faiss_file\"\n",
        "outfile=open(filepath, \"wb\")\n",
        "pickle.dump(index_ser,outfile)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lDN5YrePbBfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export dictionary\n",
        "from pathlib import Path\n",
        "filepath = Path(\"/kaggle/working\") /\"faiss_index_ids_dict\"\n",
        "outfile=open(filepath, \"wb\")\n",
        "pickle.dump(ids_dict,outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AAK3UcUzbBfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download model. Upload to datasets\n",
        "os.chdir(\"/kaggle/working\")\n",
        "os.listdir()\n",
        "from IPython.display import FileLink\n",
        "FileLink(r'index_faiss_file')\n",
        "FileLink(r'faiss_index_ids_dict')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}